
# Redes Neurais Multicamadas (MLP)

A **Rede Neural Multicamadas (MLP)**, ou Perceptron Multicamadas, √© a forma mais fundamental do Deep Learning. Ideal para dados tabulares (colunas e linhas) onde a ordem das features n√£o importa.

## üìù Conceito Chave

* √â uma rede **feedforward** (alimenta√ß√£o direta), onde a informa√ß√£o flui apenas da entrada para a sa√≠da.
* **Aprendizado (Backpropagation):** O erro da previs√£o √© propagado de volta para ajustar os **pesos** dos neur√¥nios (via otimizadores como **Adam**) e reduzir a **perda (*loss*)**.

### üß± Estrutura e Comandos Keras Essenciais

Esta se√ß√£o detalha os principais comandos do Keras, usando o MLP como exemplo.

#### A. Camada `Dense()`

A camada **`Dense`** (totalmente conectada) √© a base do MLP.

| Par√¢metro | Descri√ß√£o | Possibilidades Chave | Exemplo |
| :--- | :--- | :--- | :--- |
| **`units`** | **N√∫mero de Neur√¥nios** na camada. | Qualquer n√∫mero inteiro (Ex: 32, 64). | `units=64` |
| **`activation`** | **Fun√ß√£o de Ativa√ß√£o** do neur√¥nio. | **`'relu'`** (ocultas), **`'sigmoid'`** (sa√≠da bin√°ria), **`'softmax'`** (sa√≠da multi-classe). | `activation='relu'` |
| **`input_shape`** | **Dimens√£o da Entrada.** **S√≥ √© necess√°rio na PRIMEIRA camada.** | Tupla contendo o n√∫mero de *features* (Ex: `(10,)`). | `input_shape=(10,)` |
| **`kernel_regularizer`** | Aplica **regulariza√ß√£o L2** ou **L1** para mitigar o *overfitting*. | `'l1'`, `'l2'`. | `kernel_regularizer='l2'` |

**Exemplo**
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential()
# PRIMEIRA CAMADA (define input_shape)
model.add(Dense(units=64, activation='relu', input_shape=(10,)))
# Adiciona Regulariza√ß√£o (Dropout desliga neur√¥nios aleatoriamente)
model.add(Dropout(0.2)) 
# CAMADA OCULTA
model.add(Dense(units=32, activation='relu'))
# CAMADA DE SA√çDA
model.add(Dense(units=1, activation='sigmoid'))
```

#### Configura√ß√£o do Treinamento: `model.compile()`

Define como o modelo ser√° treinado.

| Par√¢metro | Descri√ß√£o | Possibilidades Chave | Exemplo |
| :--- | :--- | :--- | :--- |
| **`optimizer`** | **Algoritmo de Otimiza√ß√£o**. | **`'adam'`**, `'sgd'`, `'rmsprop'`. | `optimizer='adam'` |
| **`loss`** | **Fun√ß√£o de Perda** a ser minimizada. | **`'binary_crossentropy'`** (classifica√ß√£o bin√°ria), `'mse'` (regress√£o), `'categorical_crossentropy'` (multi-classe). | `loss='binary_crossentropy'` |
| **`metrics`** | **M√©tricas** de avalia√ß√£o. | `['accuracy']`, `['mae']` (regress√£o), `['Precision', 'Recall']`. | `metrics=['accuracy', 'Precision']` |

**Exemplo**
```python
from tensorflow.keras.optimizers import Adam

model.compile(optimizer=Adam(learning_rate=0.001), 
              loss='binary_crossentropy',
              metrics=['accuracy', 'Precision'])
```

#### Execu√ß√£o do Treinamento: `model.fit()`

Inicia o processo de aprendizado.

| Par√¢metro | Descri√ß√£o | Possibilidades Chave | Exemplo |
| :--- | :--- | :--- | :--- |
| **`x`, `y`** | Dados de *features* (`x`) e *labels* (`y`) de treinamento (NumPy arrays). | `x=X_train, y=y_train` |
| **`epochs`** | **N√∫mero de √©pocas** (voltas completas no *dataset*). | Inteiros (Ex: 10, 50). | `epochs=50` |
| **`batch_size`** | **N√∫mero de amostras** processadas antes de uma atualiza√ß√£o de peso. | Pot√™ncias de 2 (Ex: 32, 64). | `batch_size=64` |
| **`validation_split`** | Fra√ß√£o dos dados de treino a ser usada como valida√ß√£o (0 a 1). | `validation_split=0.15` | `validation_split=0.15` |
| **`callbacks`** | Fun√ß√µes chamadas durante o treino. | **`EarlyStopping`** (parada antecipada), **`ModelCheckpoint`** (salva o melhor modelo). | `callbacks=[es_callback]` |

```python
from tensorflow.keras.callbacks import EarlyStopping

# Define o Callback para Parada Antecipada
es_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Treinamento
history = model.fit(X_train, y_train,
                    epochs=100,
                    batch_size=64,
                    validation_split=0.15,
                    callbacks=[es_callback])
```

---
